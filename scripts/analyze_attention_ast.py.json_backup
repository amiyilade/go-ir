#!/usr/bin/env python3
"""
Script 5 (FULL): Attention-AST Alignment Analysis
Analyzes how well attention weights align with AST syntactic structure.
Based on "What Do They Capture?" paper methodology.

FULL DATASET VERSION - Supports both UniXcoder and CodeBERT.
"""

import json
import numpy as np
from pathlib import Path
from collections import defaultdict
from typing import Dict, List, Tuple
from tqdm import tqdm
import sys

# Configuration
RESULTS_DIR = Path("results")
CODE_TO_TEXT_DIR = Path("data/code-to-text")
CODE_TO_CODE_DIR = Path("data/code-to-code")
OUTPUT_DIR = RESULTS_DIR / "ast_alignment"

# Parameters from paper
ATTENTION_THRESHOLD = 0.3
MIN_HIGH_CONFIDENCE_SCORES = 100

class AttentionASTAligner:
    """Analyzes alignment between attention and AST structure."""
    
    def __init__(self):
        self.alignment_results = defaultdict(list)
    
    def load_data(self, features_file: Path, ast_file: Path, task_type: str) -> List[Dict]:
        """Load features and corresponding AST data."""
        print(f"\nLoading data...")
        print(f"  Features: {features_file.name}")
        print(f"  AST data: {ast_file.name}")
        print(f"  Task type: {task_type}")
        
        # Load features
        with open(features_file, 'r', encoding='utf-8') as f:
            features = [json.loads(line) for line in f]
        
        # Load AST data
        with open(ast_file, 'r', encoding='utf-8') as f:
            ast_data = [json.loads(line) for line in f]
        
        # Merge data
        merged = []
        for feat in features:
            sample_id = feat['sample_id']
            if sample_id < len(ast_data):
                code_label = 'code' if task_type == 'code-to-text' else 'initial_segment'
                
                if code_label in feat.get('features', {}):
                    merged.append({
                        'sample_id': sample_id,
                        'task_type': task_type,
                        'code_label': code_label,
                        'features': feat['features'][code_label],
                        'ast': ast_data[sample_id].get('ast_info', {}).get(code_label),
                        'go_constructs': ast_data[sample_id].get('go_constructs', {}).get(code_label)
                    })
        
        print(f"  ✓ Loaded {len(merged)} samples with {code_label} code")
        return merged
    
    def get_ast_parent_pairs(self, ast_tree: Dict) -> set:
        """Extract token pairs that share the same parent in AST."""
        parent_pairs = set()
        
        def traverse(node, parent_children=None):
            if 'children' in node:
                children = node['children']
                
                leaf_indices = []
                for child in children:
                    indices = self._get_leaf_indices(child)
                    leaf_indices.extend(indices)
                
                for i in range(len(leaf_indices)):
                    for j in range(i + 1, len(leaf_indices)):
                        if abs(leaf_indices[i] - leaf_indices[j]) > 1:
                            parent_pairs.add((leaf_indices[i], leaf_indices[j]))
                            parent_pairs.add((leaf_indices[j], leaf_indices[i]))
                
                for child in children:
                    traverse(child, children)
        
        if ast_tree:
            traverse(ast_tree.get('ast_tree', {}))
        
        return parent_pairs
    
    def _get_leaf_indices(self, node, current_index=None) -> List[int]:
        """Get indices of all leaf nodes under this node."""
        if current_index is None:
            current_index = [0]
        
        indices = []
        
        if 'children' not in node or len(node.get('children', [])) == 0:
            indices.append(current_index[0])
            current_index[0] += 1
        else:
            for child in node['children']:
                indices.extend(self._get_leaf_indices(child, current_index))
        
        return indices
    
    def calculate_attention_variability(self, attention_matrices: List[np.ndarray],
                                       max_tokens: int = 10) -> float:
        """Calculate attention variability (Equation 5 from paper)."""
        if len(attention_matrices) == 0:
            return 0.0
        
        truncated_attention = []
        for attn in attention_matrices:
            if attn.shape[0] >= max_tokens and attn.shape[1] >= max_tokens:
                truncated_attention.append(attn[:max_tokens, :max_tokens])
        
        if len(truncated_attention) == 0:
            return 0.0
        
        attention_array = np.stack(truncated_attention)
        mean_attention = np.mean(attention_array, axis=0)
        
        squared_diff = np.sum((attention_array - mean_attention) ** 2)
        total_attention = np.sum(attention_array)
        
        variability = squared_diff / total_attention if total_attention > 0 else 0.0
        
        return variability
    
    def calculate_alignment_score(self, attention_matrix: np.ndarray,
                                 ast_parent_pairs: set,
                                 threshold: float = ATTENTION_THRESHOLD) -> Dict:
        """Calculate p_α(f) (Equation 4 from paper)."""
        seq_len = attention_matrix.shape[0]
        
        high_attention_pairs = []
        for i in range(seq_len):
            for j in range(seq_len):
                if i != j and attention_matrix[i, j] > threshold:
                    high_attention_pairs.append((i, j))
        
        aligned_count = 0
        for pair in high_attention_pairs:
            if pair in ast_parent_pairs:
                aligned_count += 1
        
        total_high_attention = len(high_attention_pairs)
        alignment_score = aligned_count / total_high_attention if total_high_attention > 0 else 0.0
        
        return {
            'alignment_score': alignment_score,
            'aligned_pairs': aligned_count,
            'total_high_attention_pairs': total_high_attention,
            'total_ast_pairs': len(ast_parent_pairs)
        }
    
    def analyze_layer_head(self, data: List[Dict], layer_idx: int, head_idx: int) -> Dict:
        """Analyze specific layer and head across dataset."""
        layer_key = f'layer_{layer_idx}'
        head_key = f'head_{head_idx}'
        
        alignment_scores = []
        variability_matrices = []
        valid_samples = 0
        
        for sample in data:
            features = sample['features']
            ast = sample['ast']
            
            if not ast or layer_key not in features['attention_weights']:
                continue
            
            attention_matrix = np.array(
                features['attention_weights'][layer_key][head_key]
            )
            
            ast_parent_pairs = self.get_ast_parent_pairs(ast)
            
            if len(ast_parent_pairs) == 0:
                continue
            
            alignment = self.calculate_alignment_score(attention_matrix, ast_parent_pairs)
            
            if alignment['total_high_attention_pairs'] >= MIN_HIGH_CONFIDENCE_SCORES:
                alignment_scores.append(alignment['alignment_score'])
                variability_matrices.append(attention_matrix)
                valid_samples += 1
        
        if len(alignment_scores) == 0:
            return None
        
        variability = self.calculate_attention_variability(variability_matrices)
        
        return {
            'layer': layer_idx,
            'head': head_idx,
            'mean_alignment_score': np.mean(alignment_scores),
            'std_alignment_score': np.std(alignment_scores),
            'variability': variability,
            'valid_samples': valid_samples,
            'head_type': 'content-dependent' if variability > 0.25 else 'position-based'
        }
    
    def analyze_all_layers_heads(self, data: List[Dict], model_name: str) -> Dict:
        """Analyze all layers and heads for a model."""
        print(f"\nAnalyzing all layers and heads for {model_name}...")
        
        sample_features = data[0]['features']
        num_layers = len(sample_features['attention_weights'])
        num_heads = len(sample_features['attention_weights']['layer_0'])
        
        print(f"  Model: {num_layers} layers, {num_heads} heads per layer")
        
        results = []
        total_combinations = num_layers * num_heads
        
        with tqdm(total=total_combinations, desc="  Analyzing layer-head combinations") as pbar:
            for layer_idx in range(num_layers):
                for head_idx in range(num_heads):
                    result = self.analyze_layer_head(data, layer_idx, head_idx)
                    if result:
                        results.append(result)
                    pbar.update(1)
        
        print(f"  ✓ Analyzed {len(results)} valid layer-head combinations")
        
        results_sorted = sorted(results, key=lambda x: x['mean_alignment_score'], reverse=True)
        
        layer_stats = defaultdict(list)
        for result in results:
            layer_stats[result['layer']].append(result['mean_alignment_score'])
        
        layer_summary = {
            f'layer_{layer}': {
                'mean_alignment': np.mean(scores),
                'max_alignment': np.max(scores),
                'std_alignment': np.std(scores)
            }
            for layer, scores in layer_stats.items()
        }
        
        return {
            'model_name': model_name,
            'all_results': results,
            'top_10_heads': results_sorted[:10],
            'layer_summary': layer_summary,
            'overall_stats': {
                'mean_alignment': np.mean([r['mean_alignment_score'] for r in results]),
                'max_alignment': np.max([r['mean_alignment_score'] for r in results]),
                'content_dependent_heads': sum(1 for r in results if r['head_type'] == 'content-dependent'),
                'position_based_heads': sum(1 for r in results if r['head_type'] == 'position-based')
            }
        }

def main():
    """Main execution function."""
    print("\n" + "=" * 80)
    print("ATTENTION-AST ALIGNMENT ANALYSIS (RQ1) - FULL DATASET")
    print("=" * 80)
    print(f"\nParameters (from paper):")
    print(f"  Attention threshold (θ): {ATTENTION_THRESHOLD}")
    print(f"  Min high-confidence scores: {MIN_HIGH_CONFIDENCE_SCORES}")
    print(f"\nAnalyzing: UniXcoder and CodeBERT")
    print(f"Tasks: Code-to-Text and Code-to-Code")
    
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    aligner = AttentionASTAligner()
    
    # Define analysis tasks for both models
    analyses = []
    for model in ['unixcoder', 'codebert']:
        analyses.extend([
            {
                'name': f'{model}_code_to_text',
                'features': RESULTS_DIR / f"model_outputs/{model}/code_to_text_full_{model}_features.jsonl",
                'ast': CODE_TO_TEXT_DIR / "full_code_to_text_with_asts.jsonl",
                'task_type': 'code-to-text'
            },
            {
                'name': f'{model}_code_to_code',
                'features': RESULTS_DIR / f"model_outputs/{model}/code_to_code_full_{model}_features.jsonl",
                'ast': CODE_TO_CODE_DIR / "full_code_to_code_with_asts.jsonl",
                'task_type': 'code-to-code'
            }
        ])
    
    all_results = {}
    
    for analysis in analyses:
        print("\n" + "=" * 80)
        print(f"ANALYSIS: {analysis['name']}")
        print("=" * 80)
        
        if not analysis['features'].exists():
            print(f"  ✗ Features file not found: {analysis['features'].name}")
            print("    Skipping this analysis...")
            continue
        
        if not analysis['ast'].exists():
            print(f"  ✗ AST file not found: {analysis['ast'].name}")
            print("    Skipping this analysis...")
            continue
        
        data = aligner.load_data(
            analysis['features'], 
            analysis['ast'],
            analysis['task_type']
        )
        
        if len(data) == 0:
            print("  ⚠ No valid data loaded. Skipping...")
            continue
        
        results = aligner.analyze_all_layers_heads(data, analysis['name'])
        all_results[analysis['name']] = results
        
        output_file = OUTPUT_DIR / f"{analysis['name']}_alignment_results.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2)
        
        print(f"\n  ✓ Results saved to {output_file.name}")
        
        print(f"\n  [Summary Statistics]")
        print(f"    Mean alignment score: {results['overall_stats']['mean_alignment']:.3f}")
        print(f"    Max alignment score: {results['overall_stats']['max_alignment']:.3f}")
        print(f"    Content-dependent heads: {results['overall_stats']['content_dependent_heads']}")
        print(f"    Position-based heads: {results['overall_stats']['position_based_heads']}")
        
        print(f"\n  [Top 3 Aligned Heads]")
        for i, head in enumerate(results['top_10_heads'][:3]):
            print(f"    {i+1}. Layer {head['layer']}, Head {head['head']}: "
                  f"{head['mean_alignment_score']:.3f} ({head['head_type']})")
    
    combined_output = OUTPUT_DIR / "all_alignment_results.json"
    with open(combined_output, 'w', encoding='utf-8') as f:
        json.dump(all_results, f, indent=2)
    
    print("\n" + "=" * 80)
    print("✓ ALIGNMENT ANALYSIS COMPLETE")
    print("=" * 80)
    print(f"\nResults saved in: {OUTPUT_DIR}/")
    print(f"\nNext steps:")
    print(f"  1. Review alignment scores and identify best heads")
    print(f"  2. Run structural_probing_full.py for RQ2 analysis")
    print("\n")

if __name__ == "__main__":
    main()
