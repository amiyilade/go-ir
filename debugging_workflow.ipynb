{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üêõ Debugging Workflow for Go-Eval Project\n",
    "\n",
    "Use this notebook for iterative development and debugging.\n",
    "\n",
    "**Workflow:**\n",
    "1. Edit code on GitHub (or locally and push)\n",
    "2. Run \"Pull Latest Changes\" cell below\n",
    "3. Run your specific script\n",
    "4. Check errors\n",
    "5. Repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Setup (Run Once Per Session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch transformers datasets tree-sitter tree-sitter-go scipy scikit-learn matplotlib seaborn tqdm networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (for persistence)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Initial Clone (Run Only ONCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone to Google Drive for persistence\n",
    "%cd /content/drive/MyDrive\n",
    "!git clone https://github.com/amiyilade/go-eval.git\n",
    "%cd go-eval\n",
    "\n",
    "print(\"‚úÖ Repository cloned to Google Drive\")\n",
    "print(\"üìÅ Location: /content/drive/MyDrive/go-eval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Pull Latest Changes (Run Every Time You Make Changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate to repo\n",
    "%cd /content/drive/MyDrive/go-eval\n",
    "\n",
    "# Discard any local changes (if you edited files in Colab)\n",
    "!git reset --hard HEAD\n",
    "\n",
    "# Pull latest from GitHub\n",
    "!git pull origin main\n",
    "\n",
    "# Show last 3 commits to verify\n",
    "print(\"\\nüìù Latest commits:\")\n",
    "!git log --oneline -3\n",
    "\n",
    "print(\"\\n‚úÖ Code updated to latest version\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Test Individual Scripts\n",
    "\n",
    "Run these cells to test specific scripts after making changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Download data (quick test - will only download if not exists)\n",
    "!python scripts/download_coir_go.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Organize data\n",
    "!python scripts/organise_coir_go_full.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Parse ASTs (this takes ~45 min on full dataset)\n",
    "# Use Ctrl+C to stop if you just want to test it runs\n",
    "!python scripts/parse_go_asts_full.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Extract model features - UniXcoder\n",
    "!python scripts/extract_model_outputs_full.py --model unixcoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Extract model features - CodeBERT\n",
    "!python scripts/extract_model_outputs_full.py --model codebert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Attention-AST alignment analysis\n",
    "!python scripts/analyze_attention_ast_full.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Structural probing\n",
    "!python scripts/structural_probing_full.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Tree induction\n",
    "!python scripts/tree_induction_full.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Construct analysis\n",
    "!python scripts/construct_analysis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Cross-model analysis\n",
    "!python scripts/cross_model_analysis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Visualizations\n",
    "!python scripts/visualizations_full.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Debugging Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what files exist\n",
    "!ls -lh data/\n",
    "!ls -lh results/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Python imports work\n",
    "import torch\n",
    "import transformers\n",
    "import tree_sitter\n",
    "import tree_sitter_go\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import seaborn\n",
    "\n",
    "print(\"‚úÖ All imports successful\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Transformers version: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ùå No GPU available\")\n",
    "    print(\"   Go to Runtime > Change runtime type > Select T4 GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View error logs from specific script\n",
    "# Replace 'script_name' with the script that's failing\n",
    "!tail -50 results/logs/script_name.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßπ Cleanup (If Needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all results (to start fresh)\n",
    "# WARNING: This deletes all analysis results!\n",
    "!rm -rf results/\n",
    "print(\"üóëÔ∏è All results deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete data (to re-download)\n",
    "# WARNING: This deletes all downloaded data!\n",
    "!rm -rf data/\n",
    "print(\"üóëÔ∏è All data deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nuclear option: Delete repo and re-clone\n",
    "# WARNING: This deletes EVERYTHING!\n",
    "%cd /content/drive/MyDrive\n",
    "!rm -rf go-eval\n",
    "!git clone https://github.com/amiyilade/go-eval.git\n",
    "%cd go-eval\n",
    "print(\"üóëÔ∏è Repository deleted and re-cloned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Quick Status Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what's been completed\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "checks = [\n",
    "    (\"Data downloaded\", Path(\"data/raw/codesearchnet/consolidated.jsonl\")),\n",
    "    (\"Data organized\", Path(\"data/code-to-text/full_code_to_text.jsonl\")),\n",
    "    (\"ASTs parsed\", Path(\"data/code-to-text/full_code_to_text_with_asts.jsonl\")),\n",
    "    (\"UniXcoder features\", Path(\"results/model_outputs/unixcoder/code_to_text_full_unixcoder_features.jsonl\")),\n",
    "    (\"CodeBERT features\", Path(\"results/model_outputs/codebert/code_to_text_full_codebert_features.jsonl\")),\n",
    "    (\"Alignment results\", Path(\"results/ast_alignment/all_alignment_results.json\")),\n",
    "    (\"Probing results\", Path(\"results/structural_probing/all_probing_results.json\")),\n",
    "    (\"Induction results\", Path(\"results/tree_induction/all_tree_induction_results.json\")),\n",
    "    (\"Construct results\", Path(\"results/construct_analysis/all_construct_analysis.json\")),\n",
    "    (\"Cross-model results\", Path(\"results/cross_model_analysis/all_cross_model_analysis.json\")),\n",
    "    (\"Visualizations\", Path(\"results/visualizations/fig1_alignment_heatmap.png\")),\n",
    "]\n",
    "\n",
    "print(\"Pipeline Status:\")\n",
    "print(\"=\" * 50)\n",
    "for name, path in checks:\n",
    "    status = \"‚úÖ\" if path.exists() else \"‚ùå\"\n",
    "    print(f\"{status} {name}\")\n",
    "    if path.exists():\n",
    "        size = path.stat().st_size / (1024*1024)  # MB\n",
    "        print(f\"   Size: {size:.2f} MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
